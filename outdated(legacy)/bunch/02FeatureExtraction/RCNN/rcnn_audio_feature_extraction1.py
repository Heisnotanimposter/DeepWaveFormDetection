# -*- coding: utf-8 -*-
"""RCNN_Audio_Feature_Extraction1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xfyYMJeoiA9YjhgX659LW_Ge1v7Ca7uB
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install librosa
!pip install torchaudio

# Import libraries
import os
import numpy as np
import pandas as pd
import librosa
import torch
import torch.nn as nn
import torchaudio
import torchvision
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Define dataset paths
dataset_path = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/cv-corpus-17.0-delta-2024-03-15/en'

# Load metadata
metadata_path = os.path.join(dataset_path, '#path.csv')
metadata = pd.read_csv(metadata_path)

# Function to preprocess audio
def preprocess_audio(file_path, max_length=128):
    y, sr = librosa.load(file_path, sr=None)
    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)

    if mel_spectrogram_db.shape[1] > max_length:
        mel_spectrogram_db = mel_spectrogram_db[:, :max_length]
    else:
        pad_width = max_length - mel_spectrogram_db.shape[1]
        mel_spectrogram_db = np.pad(mel_spectrogram_db, ((0, 0), (0, pad_width)), mode='constant')

    return mel_spectrogram_db

# Apply preprocessing
metadata['path'] = metadata['path'].apply(lambda x: os.path.join(dataset_path, x))
metadata['features'] = metadata['path'].apply(preprocess_audio)

# Verify the shapes of the mel spectrograms
shapes = [feature.shape for feature in metadata['features'].values]
print(set(shapes))  # Should print a single shape, indicating all arrays are the same size

# Flatten the features
metadata['features'] = metadata['features'].apply(lambda x: x.flatten())

# Extract features and labels
X = np.stack(metadata['features'].values)
y_client_id = metadata['client_id']  # Fake voice detection label

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y_client_id, test_size=0.2, random_state=42)

# Define the model (Faster RCNN)
class FakeVoiceDetectionModel(nn.Module):
    def __init__(self):
        super(FakeVoiceDetectionModel, self).__init__()
        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.fc1 = nn.Linear(64 * 64 * 64, 128)
        self.fc2 = nn.Linear(128, 1)

    def forward(self, x):
        x = self.pool(F.gelu(self.conv1(x)))
        x = x.view(-1, 64 * 64 * 64)
        x = F.gelu(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))
        return x

# Instantiate the model, define loss function and optimizer
model = FakeVoiceDetectionModel()
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Convert data to PyTorch tensors and reshape for convolutional layers
X_train_tensor = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 1, 128, 128)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32).reshape(-1, 1, 128, 128)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)

# Training loop
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    optimizer.zero_grad()
    outputs = model(X_train_tensor)
    loss = criterion(outputs, y_train_tensor)
    loss.backward()
    optimizer.step()

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}")

# Evaluation function
def evaluate_model(model, X_test, y_test):
    model.eval()
    with torch.no_grad():
        outputs = model(X_test)
        predicted = (outputs >= 0.5).float()
        accuracy = accuracy_score(y_test, predicted)
        precision = precision_score(y_test, predicted, average='weighted')
        recall = recall_score(y_test, predicted, average='weighted')
        f1 = f1_score(y_test, predicted, average='weighted')
        print(f"Accuracy: {accuracy:.4f}")
        print(f"Precision: {precision:.4f}")
        print(f"Recall: {recall:.4f}")
        print(f"F1 Score: {f1:.4f}")

# Evaluate the model
evaluate_model(model, X_test_tensor, y_test_tensor)

