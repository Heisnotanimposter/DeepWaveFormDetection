# -*- coding: utf-8 -*-
"""CloneVoiceGenerativeAdversarialNeuralNetwork.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yXZO5WQIdame21AOekOVVYsgbAKoZ7_Z
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import librosa
import matplotlib.pyplot as plt
from google.colab import drive
import glob
import os
import cv2
from torch.autograd import Variable

drive.mount('/content/drive')

# Define paths
real_dataset_path = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/KaggleDataset/real'
fake_dataset_path = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/KaggleDataset/fake'

# Function to load and preprocess audio data
def load_audio_and_preprocess(file_path, sr=22050, max_length=128):
    y, _ = librosa.load(file_path, sr=sr)
    stft = librosa.stft(y)
    spectrogram = librosa.amplitude_to_db(np.abs(stft), ref=np.max)

    if spectrogram.shape[1] < max_length:
        spectrogram = np.pad(spectrogram, pad_width=((0, 0), (0, max_length - spectrogram.shape[1])), mode='constant')
    else:
        spectrogram = spectrogram[:, :max_length]

    spectrogram = (spectrogram - np.min(spectrogram)) / (np.max(spectrogram) - np.min(spectrogram))
    spectrogram = cv2.resize(spectrogram, (128, 128))
    return spectrogram

# Load and preprocess data
real_spectrograms = [load_audio_and_preprocess(file) for file in glob.glob(real_dataset_path + '/*.wav')]
fake_spectrograms = [load_audio_and_preprocess(file) for file in glob.glob(fake_dataset_path + '/*.wav')]

# Create labels and combine data
all_spectrograms = np.concatenate([real_spectrograms, fake_spectrograms])
all_labels = np.concatenate([np.ones(len(real_spectrograms)), np.zeros(len(fake_spectrograms))])

# Shuffle data
shuffle_indices = np.random.permutation(len(all_spectrograms))
all_spectrograms = all_spectrograms[shuffle_indices]
all_labels = all_labels[shuffle_indices]

# Convert to PyTorch tensors and create DataLoader
all_spectrograms_tensor = torch.tensor(all_spectrograms, dtype=torch.float32).unsqueeze(1)
all_labels_tensor = torch.tensor(all_labels, dtype=torch.float32).unsqueeze(1)
dataset = torch.utils.data.TensorDataset(all_spectrograms_tensor, all_labels_tensor)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)


# Define GAN Architecture
class Generator(nn.Module):
    def __init__(self, input_dim=100, output_channels=1, image_size=128):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d(input_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d(64, output_channels, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        return self.main(input)

class Discriminator(nn.Module):
    def __init__(self, input_channels=1, image_size=128):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(input_channels, 64, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(64, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
        )
        self.flatten = nn.Flatten()
        self.linear_layers = nn.Sequential(
            nn.Linear(512 * 8 * 8, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1024, 1),
            nn.Sigmoid()
        )

    def forward(self, input):
        x = self.main(input)
        x = self.flatten(x)
        return self.linear_layers(x)


# Training Loop
def train_gan(generator, discriminator, dataloader, num_epochs=100, lr=0.0002, device="cuda"):
    criterion = nn.MSELoss()  # Least Squares Loss for WaveGAN
    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

    # Fixed noise for visualization
    fixed_noise = torch.randn(64, 100, 1, 1, device=device)

    for epoch in range(num_epochs):
        for i, (images, _) in enumerate(dataloader): # _ for unused labels
            images = images.to(device)

            # Train Discriminator with all-real batch
            discriminator.zero_grad()
            real_labels = torch.ones(images.size(0), 1, device=device)
            output = discriminator(images)
            errD_real = criterion(output, real_labels)
            errD_real.backward()

            # Train Discriminator with all-fake batch
            noise = torch.randn(images.size(0), 100, 1, 1, device=device)
            fake = generator(noise)
            fake_labels = torch.zeros(images.size(0), 1, device=device)
            output = discriminator(fake.detach())
            errD_fake = criterion(output, fake_labels)
            errD_fake.backward()

            errD = errD_real + errD_fake
            optimizer_D.step()

            # Train Generator
            generator.zero_grad()
            output = discriminator(fake)
            errG = criterion(output, real_labels)  # Try to make discriminator classify fakes as real
            errG.backward()
            optimizer_G.step()

            # Output training stats
            if i % 50 == 0:
                print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}]\tLoss_D: {errD.item():.4f}\tLoss_G: {errG.item():.4f}')

    return generator

# Initialize models and determine device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator = Generator().to(device)
discriminator = Discriminator().to(device)
print(f"Using device: {device}")

# Train GAN
generator = train_gan(generator, discriminator, dataloader, device=device)

# Generate spectrograms
generated_spectrograms = generator(fixed_noise).detach().cpu()

# Visualize generated spectrograms (only first 9 for demonstration)
plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(generated_spectrograms[i].squeeze(0), cmap='viridis', origin='lower', aspect='auto')  # Assuming the spectrogram is the first channel
    plt.title(f'Generated Spectrogram {i + 1}')
    plt.axis('off')

plt.show()

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import librosa
import matplotlib.pyplot as plt
from google.colab import drive
import glob
import os
import cv2
from torch.autograd import Variable, grad

drive.mount('/content/drive')

# Define paths (Replace with your actual paths)
real_dataset_path = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/KaggleDataset/real'
fake_dataset_path = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/KaggleDataset/fake'
GENERATED_PATH = '/content/drive/MyDrive/generated'
CHECKPOINT_PATH = '/content/drive/MyDrive/model_checkpoints'

# Hyperparameters
num_epochs = 100
learning_rate = 0.0002
batch_size = 64
latent_dim = 100  # Noise dimension for generator
LAMBDA_GP = 10   # Gradient penalty coefficient

# Function to load and preprocess audio data
def load_audio_and_preprocess(file_path, sr=22050, max_length=128):
    y, _ = librosa.load(file_path, sr=sr)
    stft = librosa.stft(y)
    spectrogram = librosa.amplitude_to_db(np.abs(stft), ref=np.max)

    if spectrogram.shape[1] < max_length:
        spectrogram = np.pad(spectrogram, pad_width=((0, 0), (0, max_length - spectrogram.shape[1])), mode='constant')
    else:
        spectrogram = spectrogram[:, :max_length]

    spectrogram = (spectrogram - np.min(spectrogram)) / (np.max(spectrogram) - np.min(spectrogram))
    spectrogram = cv2.resize(spectrogram, (128, 128))
    return spectrogram

# Load and preprocess data
real_spectrograms = [load_audio_and_preprocess(file) for file in glob.glob(real_dataset_path + '/*.wav')]
fake_spectrograms = [load_audio_and_preprocess(file) for file in glob.glob(fake_dataset_path + '/*.wav')]
all_spectrograms = np.concatenate([real_spectrograms, fake_spectrograms])
all_labels = np.concatenate([np.ones(len(real_spectrograms)), np.zeros(len(fake_spectrograms))])

# Shuffle data
shuffle_indices = np.random.permutation(len(all_spectrograms))
all_spectrograms = all_spectrograms[shuffle_indices]
all_labels = all_labels[shuffle_indices]

# Convert to PyTorch tensors and create DataLoader
all_spectrograms_tensor = torch.tensor(all_spectrograms, dtype=torch.float32).unsqueeze(1)
all_labels_tensor = torch.tensor(all_labels, dtype=torch.float32).unsqueeze(1)
dataset = torch.utils.data.TensorDataset(all_spectrograms_tensor, all_labels_tensor)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)

# ... (PhaseShuffle, Generator, and Discriminator classes remain the same)

# Training Loop (Modified with WGAN-GP and Phase Shuffle)
def train_gan(generator, discriminator, dataloader, num_epochs=num_epochs, lr=learning_rate, device="cuda"):
    criterion = nn.MSELoss()  # Least Squares Loss for WaveGAN

    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

    # Fixed noise for visualization
    fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)

    for epoch in range(num_epochs):
        for i, (real_samples, _) in enumerate(dataloader):
            real_samples = real_samples.to(device)

            # Train Discriminator
            optimizer_D.zero_grad()
            # Real samples
            real_validity = discriminator(real_samples)
            # Fake samples
            z = torch.randn(batch_size, latent_dim, 1, 1, device=device)
            fake_samples = generator(z)
            fake_validity = discriminator(fake_samples)

            # Gradient penalty
            gradient_penalty = compute_gradient_penalty(discriminator, real_samples.data, fake_samples.data, device)

            # Adversarial loss (WGAN-GP)
            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + LAMBDA_GP * gradient_penalty
            d_loss.backward()
            optimizer_D.step()

            # Train Generator every n_critic steps
            if i % 5 == 0:
                optimizer_G.zero_grad()
                fake_samples = generator(z)
                fake_validity = discriminator(fake_samples)
                g_loss = -torch.mean(fake_validity)
                g_loss.backward()
                optimizer_G.step()

            # ... (your existing code to print loss and visualize the generated spectrograms)


# Function to compute gradient penalty (for WGAN-GP)
def compute_gradient_penalty(D, real_samples, fake_samples, device):
    # ... (Implementation of gradient penalty from WaveGAN code)

# ... (rest of the code for initializing models, training, and visualization)

# ... (Your previous code: import statements, data loading, GAN architectures)

# Function to compute gradient penalty (for WGAN-GP)
def compute_gradient_penalty(D, real_samples, fake_samples, device):
    """Calculates the gradient penalty loss for WGAN GP"""
    # Random weight term for interpolation between real and fake samples
    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)
    # Get random interpolation between real and fake samples
    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)
    d_interpolates = D(interpolates)
    fake = torch.ones(real_samples.size(0), 1, device=device)
    # Get gradient w.r.t. interpolates
    gradients = grad(
        outputs=d_interpolates,
        inputs=interpolates,
        grad_outputs=fake,
        create_graph=True,
        retain_graph=True,
        only_inputs=True,
    )[0]
    gradients = gradients.view(gradients.size(0), -1)
    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
    return gradient_penalty

# Training Loop (Modified with WGAN-GP and Phase Shuffle)
def train_gan(generator, discriminator, dataloader, num_epochs=num_epochs, lr=learning_rate, device="cuda"):
    criterion = nn.MSELoss()  # Least Squares Loss for WaveGAN
    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

    # Fixed noise for visualization
    fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)

    for epoch in range(num_epochs):
        for i, (real_samples, _) in enumerate(dataloader):
            real_samples = real_samples.to(device)

            # Train Discriminator
            optimizer_D.zero_grad()
            # Real samples
            real_validity = discriminator(real_samples)
            # Fake samples
            z = torch.randn(batch_size, latent_dim, 1, 1, device=device)
            fake_samples = generator(z)
            fake_validity = discriminator(fake_samples)

            # Gradient penalty
            gradient_penalty = compute_gradient_penalty(discriminator, real_samples.data, fake_samples.data, device)

            # Adversarial loss (WGAN-GP)
            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + LAMBDA_GP * gradient_penalty
            d_loss.backward()
            optimizer_D.step()

            # Train Generator every n_critic steps
            if i % 5 == 0:
                optimizer_G.zero_grad()
                fake_samples = generator(z)
                fake_validity = discriminator(fake_samples)
                g_loss = -torch.mean(fake_validity)
                g_loss.backward()
                optimizer_G.step()

            # Output training stats
            if i % 100 == 0:
                print(f"Epoch [{epoch}/{num_epochs}] Batch {i}/{len(dataloader)} \
                      Loss D: {d_loss:.4f}, loss G: {g_loss:.4f}")

                with torch.no_grad():
                    fake = generator(fixed_noise).detach().cpu()
                    img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)
                    save_image(img_grid_fake, os.path.join(GENERATED_PATH, f'image_at_epoch_{epoch:04d}_batch_{i:04d}.png'))
                    torch.save({
                        'epoch': epoch,
                        'generator_state_dict': generator.state_dict(),
                        'discriminator_state_dict': discriminator.state_dict(),
                        'optimizer_G_state_dict': optimizer_G.state_dict(),
                        'optimizer_D_state_dict': optimizer_D.state_dict(),
                        'loss_G': g_loss,
                        'loss_D': d_loss,
                    }, os.path.join(CHECKPOINT_PATH, f'checkpoint_epoch_{epoch:04d}_batch_{i:04d}.pth'))

    return generator
# ... (rest of the code for initializing models, training, and visualization)