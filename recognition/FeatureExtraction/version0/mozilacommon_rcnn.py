# -*- coding: utf-8 -*-
"""MozilaCommon_RCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w5f7KM-ZmSV2QJV5LiLFS5OSvQtnCA3v
"""

#kaggle dataset control

"""
! pip install kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import shutil
from urllib.parse import unquote, urlparse
import pandas as pd
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import warnings

import seaborn as sns
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')

# Define data source mapping (replace with your Google Drive file paths)
data_source_mapping = 'voice-dataset:/content/drive/MyDrive/voice_dataset/voice_file_1.zip,voice-dataset:/content/drive/MyDrive/voice_dataset/voice_file_2.tar.gz'

# Set the path to the dataset
dataset_path = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/cv-corpus-17.0-delta-2024-03-15/en/clips'
metadata_path = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/cv-corpus-17.0-delta-2024-03-15/en/validated.tsv'
#os.makedirs(dataset_path, exist_ok=True)
#os.makedirs(metadata_path, exist_ok=True)

# Load the metadata
metadata = pd.read_csv(metadata_path, sep='\t')
metadata.head()

CHUNK_SIZE = 40960

# Function to extract datasets from Google Drive paths
def extract_files(data_source_mapping, input_path):
    for data_source in data_source_mapping.split(','):
        directory, file_path = data_source.split(':')
        destination_path = os.path.join(input_path, directory)
        try:
            if file_path.endswith('.zip'):
                with ZipFile(file_path, 'r') as zfile:
                    zfile.extractall(destination_path)
            elif file_path.endswith('.tar.gz') or file_path.endswith('.tgz'):
                with tarfile.open(file_path, 'r:gz') as tarfile:
                    tarfile.extractall(destination_path)
            else:
                print(f'Unsupported file format for {file_path}')
            print(f'Extracted: {file_path} to {destination_path}')
        except Exception as e:
            print(f'Failed to extract {file_path} to path {destination_path}: {e}')
            continue

print('Starting data source extraction...')
extract_files(data_source_mapping, dataset_path)
print('Data source extraction complete.')

def preprocess_audio(file_path, max_length=128):
    y, sr = librosa.load(file_path, sr=None)
    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)

    # Pad or truncate the mel spectrogram to ensure consistent shape
    if mel_spectrogram_db.shape[1] > max_length:
        mel_spectrogram_db = mel_spectrogram_db[:, :max_length]
    else:
        pad_width = max_length - mel_spectrogram_db.shape[1]
        mel_spectrogram_db = np.pad(mel_spectrogram_db, ((0, 0), (0, pad_width)), mode='constant')

    return mel_spectrogram_db

# Apply the updated preprocess_audio function
metadata['path'] = metadata['path'].apply(lambda x: os.path.join(dataset_path, x))
metadata['features'] = metadata['path'].apply(preprocess_audio)

# Extract features and labels
X = np.stack(metadata['features'].values)
y_client_id = metadata['client_id']
y_age = metadata['age']
y_accents = metadata['accents']

# Verify the shapes of the mel spectrograms
shapes = [feature.shape for feature in metadata['features'].values]
print(set(shapes))  # Should print a single shape, indicating all arrays are the same size

# Now proceed with model training and evaluation
# For example, using the previously defined evaluate_model function
from sklearn.model_selection import train_test_split

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y_client_id, test_size=0.2, random_state=42)

# Example with Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
evaluate_model(dt, X_train, X_test, y_train, y_test, "Decision Tree")

# You can repeat the process with other classifiers as needed

label_encoder_gender = LabelEncoder()
label_encoder_age = LabelEncoder()
label_encoder_nationality = LabelEncoder()

y_gender_encoded = label_encoder_gender.fit_transform(y_gender)
y_age_encoded = label_encoder_age.fit_transform(y_age)
y_nationality_encoded = label_encoder_nationality.fit_transform(y_nationality)

X_train, X_test, y_gender_train, y_gender_test = train_test_split(X, y_gender_encoded, test_size=0.2, random_state=42)
X_train, X_test, y_age_train, y_age_test = train_test_split(X, y_age_encoded, test_size=0.2, random_state=42)
X_train, X_test, y_nationality_train, y_nationality_test = train_test_split(X, y_nationality_encoded, test_size=0.2, random_state=42)

class AudioDataset(Dataset):
    def __init__(self, features, labels):
        self.features = features
        self.labels = labels

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)

train_dataset_gender = AudioDataset(X_train, y_gender_train)
test_dataset_gender = AudioDataset(X_test, y_gender_test)

train_loader_gender = DataLoader(train_dataset_gender, batch_size=32, shuffle=True)
test_loader_gender = DataLoader(test_dataset_gender, batch_size=32, shuffle=False)

# Repeat for age and nationality
train_dataset_age = AudioDataset(X_train, y_age_train)
test_dataset_age = AudioDataset(X_test, y_age_test)
train_loader_age = DataLoader(train_dataset_age, batch_size=32, shuffle=True)
test_loader_age = DataLoader(test_dataset_age, batch_size=32, shuffle=False)

train_dataset_nationality = AudioDataset(X_train, y_nationality_train)
test_dataset_nationality = DataLoader(test_dataset_nationality, batch_size=32, shuffle=True)
test_loader_nationality = DataLoader(test_dataset_nationality, batch_size=32, shuffle=False)

class RCNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2):
        super(RCNN, self).__init__()
        self.cnn = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(hidden_dim * 2, output_dim)

    def forward(self, x):
        x = x.unsqueeze(1)
        x = self.pool(F.relu(self.cnn(x)))
        x = x.permute(0, 2, 1, 3)
        x = x.reshape(x.size(0), x.size(1), -1)
        h0 = torch.zeros(4, x.size(0), 128).to(x.device)
        c0 = torch.zeros(4, x.size(0), 128).to(x.device)
        x, _ = self.rnn(x, (h0, c0))
        x = self.fc(x[:, -1, :])
        return x

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
num_classes_gender = len(label_encoder_gender.classes_)
num_classes_age = len(label_encoder_age.classes_)
num_classes_nationality = len(label_encoder_nationality.classes_)

# Define models
model_gender = RCNN(input_dim=128, hidden_dim=128, output_dim=num_classes_gender).to(device)
model_age = RCNN(input_dim=128, hidden_dim=128, output_dim=num_classes_age).to(device)
model_nationality = RCNN(input_dim=128, hidden_dim=128, output_dim=num_classes_nationality).to(device)

criterion = nn.CrossEntropyLoss()
optimizer_gender = optim.Adam(model_gender.parameters(), lr=0.001)
optimizer_age = optim.Adam(model_age.parameters(), lr=0.001)
optimizer_nationality = optim.Adam(model_nationality.parameters(), lr=0.001)

def train_model(model, train_loader, criterion, optimizer, num_epochs=10):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for features, labels in train_loader:
            features, labels = features.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * features.size(0)
        epoch_loss = running_loss / len(train_loader.dataset)
        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')

train_model(model_gender, train_loader_gender, criterion, optimizer_gender)
train_model(model_age, train_loader_age, criterion, optimizer_age)
train_model(model_nationality, train_loader_nationality, criterion, optimizer_nationality)

def evaluate_model(model, test_loader):
    model.eval()
    y_true = []
    y_pred = []
    with torch.no_grad():
        for features, labels in test_loader:
            features, labels = features.to(device), labels.to(device)
            outputs = model(features)
            _, preds = torch.max(outputs, 1)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())
    return y_true, y_pred

# Evaluate Gender model
y_true_gender, y_pred_gender = evaluate_model(model_gender, test_loader_gender)
accuracy_gender = accuracy_score(y_true_gender, y_pred_gender)
precision_gender = precision_score(y_true_gender, y_pred_gender, average='weighted')
recall_gender = recall_score(y_true_gender, y_pred_gender, average='weighted')
f1_gender = f1_score(y_true_gender, y_pred_gender, average='weighted')

print(f'Gender Classification - Accuracy: {accuracy_gender:.4f}, Precision: {precision_gender:.4f}, Recall: {recall_gender:.4f}, F1 Score: {f1_gender:.4f}')

# Evaluate Age model
y_true_age, y_pred_age = evaluate_model(model_age, test_loader_age)
accuracy_age = accuracy_score(y_true_age, y_pred_age)
precision_age = precision_score(y_true_age, y_pred_age, average='weighted')
recall_age = recall_score(y_true_age, y_pred_age, average='weighted')
f1_age = f1_score(y_true_age, y_pred_age, average='weighted')

print(f'Age Classification - Accuracy:

# Evaluate Nationality model
y_true_nationality, y_pred_nationality = evaluate_model(model_nationality, test_loader_nationality)
accuracy_nationality = accuracy_score(y_true_nationality, y_pred_nationality)
precision_nationality = precision_score(y_true_nationality, y_pred_nationality, average='weighted')
recall_nationality = recall_score(y_true_nationality, y_pred_nationality, average='weighted')
f1_nationality = f1_score(y_true_nationality, y_pred_nationality, average='weighted')

print(f'Nationality Classification - Accuracy: {accuracy_nationality:.4f}, Precision: {precision_nationality:.4f}, Recall: {recall_nationality:.4f}, F1 Score: {f1_nationality:.4f}')

# Assuming human_score and generation_score columns exist
# For demonstration purposes, let's create some synthetic scores
np.random.seed(42)
metadata['human_score'] = np.random.rand(len(metadata))
metadata['generation_score'] = np.random.rand(len(metadata))

# Normalize scores to be between 0 and 1
metadata['human_score'] = (metadata['human_score'] - metadata['human_score'].min()) / (metadata['human_score'].max() - metadata['human_score'].min())
metadata['generation_score'] = (metadata['generation_score'] - metadata['generation_score'].min()) / (metadata['generation_score'].max() - metadata['generation_score'].min())

# Extract scores as labels
y_human_score = metadata['human_score'].values
y_generation_score = metadata['generation_score'].values

# Train-test split for human and generation scores
X_train, X_test, y_human_train, y_human_test = train_test_split(X, y_human_score, test_size=0.2, random_state=42)
X_train, X_test, y_generation_train, y_generation_test = train_test_split(X, y_generation_score, test_size=0.2, random_state=42)

train_dataset_human = AudioDataset(X_train, y_human_train)
test_dataset_human = AudioDataset(X_test, y_human_test)

train_loader_human = DataLoader(train_dataset_human, batch_size=32, shuffle=True)
test_loader_human = DataLoader(test_dataset_human, batch_size=32, shuffle=False)

train_dataset_generation = AudioDataset(X_train, y_generation_train)
test_dataset_generation = DataLoader(test_dataset_generation, batch_size=32, shuffle=True)
test_loader_generation = DataLoader(test_dataset_generation, batch_size=32, shuffle=False)

# Define regression model
class RCNNRegressor(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2):
        super(RCNNRegressor, self).__init__()
        self.cnn = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(hidden_dim * 2, output_dim)

    def forward(self, x):
        x = x.unsqueeze(1)
        x = self.pool(F.relu(self.cnn(x)))
        x = x.permute(0, 2, 1, 3)
        x = x.reshape(x.size(0), x.size(1), -1)
        h0 = torch.zeros(4, x.size(0), 128).to(x.device)
        c0 = torch.zeros(4, x.size(0), 128).to(x.device)
        x, _ = self.rnn(x, (h0, c0))
        x = self.fc(x[:, -1, :])
        return x

model_human = RCNNRegressor(input_dim=128, hidden_dim=128, output_dim=1).to(device)
model_generation = RCNNRegressor(input_dim=128, hidden_dim=128, output_dim=1).to(device)

criterion_regression = nn.MSELoss()
optimizer_human = optim.Adam(model_human.parameters(), lr=0.001)
optimizer_generation = optim.Adam(model_generation.parameters(), lr=0.001)

# Train regression models
train_model(model_human, train_loader_human, criterion_regression, optimizer_human)
train_model(model_generation, train_loader_generation, criterion_regression, optimizer_generation)

# Evaluate regression models
def evaluate_regression_model(model, test_loader):
    model.eval()
    y_true = []
    y_pred = []
    with torch.no_grad():
        for features, labels in test_loader:
            features, labels = features.to(device), labels.to(device)
            outputs = model(features)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(outputs.cpu().numpy())
    return y_true, y_pred

y_true_human, y_pred_human = evaluate_regression_model(model_human, test_loader_human)
y_true_generation, y_pred_generation = evaluate_regression_model(model_generation, test_loader_generation)

# Compute regression metrics
from sklearn.metrics import mean_squared_error, r2_score

mse_human = mean_squared_error(y_true_human, y_pred_human)
r2_human = r2_score(y_true_human, y_pred_human)
print(f'Human Score Regression - MSE: {mse_human:.4f}, R2 Score: {r2_human:.4f}')

mse_generation = mean_squared_error(y_true_generation, y_pred_generation)
r2_generation = r2_score(y_true_generation, y_pred_generation)
print(f'Generation Score Regression - MSE: {mse_generation:.4f}, R2 Score: {r2_generation:.4f}')

# Plotting Gender classification results
sns.heatmap(confusion_matrix(y_true_gender, y_pred_gender), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix for Gender Classification')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Plotting Age classification results
sns.heatmap(confusion_matrix(y_true_age, y_pred_age), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix for Age Classification')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Plotting Nationality classification results
sns.heatmap(confusion_matrix(y_true_nationality, y_pred_nationality), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix for Nationality Classification')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Plotting Human Score regression results
plt.scatter(y_true_human, y_pred_human, alpha=0.3)
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.title('Human Score Regression')
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.show()

# Plotting Generation Score regression results
plt.scatter(y_true_generation, y_pred_generation, alpha=0.3)
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.title('Generation Score Regression')
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.show()

# Decision Tree
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)
print("Decision Tree Classifier Metrics:")
print_metrics(y_test, y_pred_dt)
eval(y_pred_dt, y_test)

# Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
print("\nLogistic Regression Metrics:")
print_metrics(y_test, y_pred_lr)
eval(y_pred_lr, y_test)

# Support Vector Machine
svc = SVC()
svc.fit(X_train, y_train)
y_pred_svc = svc.predict(X_test)
print("\nSupport Vector Machine Metrics:")
print_metrics(y_test, y_pred_svc)
eval(y_pred_svc, y_test)

# K-Nearest Neighbors
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print("\nK-Nearest Neighbors Metrics:")
print_metrics(y_test, y_pred_knn)
eval(y_pred_knn, y_test)

# Random Forest
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
print("\nRandom Forest Metrics:")
print_metrics(y_test, y_pred_rf)
eval(y_pred_rf, y_test)

# Assuming 'label' is the gender column and other columns are acoustic features
X = combined_csv.drop(columns=['clips_count'])
y = combined_csv['client_id']

#sns.pairplot(combined_csv, hue='gender')
#plt.show()

#sns.boxplot(x='gender', y='meanfreq', data=combined_csv)
#plt.show()

sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.show()