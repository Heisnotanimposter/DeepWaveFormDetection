{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OqIbixpedFCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFQiGZ7OamZn",
        "outputId": "fa533944-b416-4bb0-c3b2-dc18a5c0ae35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAPLZMc2aeOR"
      },
      "outputs": [],
      "source": [
        "#libraries\n",
        "import csv\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.exceptions import NotFittedError\n",
        "\n",
        "\"\"\"\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = '/path/to/mozila_common_voice'\n",
        "metadata = pd.read_csv(os.path.join(dataset_path, 'validated.tsv'), sep='\\t')\n",
        "\n",
        "# Display the first few rows\n",
        "print(metadata.head())\n",
        "\n",
        "# Clean the dataset by dropping rows with missing values\n",
        "metadata_clean = metadata.dropna()\n",
        "\n",
        "# Encode the 'client_id' or any other categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "metadata_clean['client_id_encoded'] = label_encoder.fit_transform(metadata_clean['client_id'])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom label encoder to handle unseen labels\n",
        "class ExtendedLabelEncoder(LabelEncoder):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.classes_ = None\n",
        "\n",
        "    def fit(self, y):\n",
        "        super().fit(y)\n",
        "        self.classes_ = super().classes_\n",
        "\n",
        "    def transform(self, y):\n",
        "        try:\n",
        "            return super().transform(y)\n",
        "        except NotFittedError:\n",
        "            raise\n",
        "        except ValueError as e:\n",
        "            unseen_label = max(self.classes_) + 1\n",
        "            self.classes_ = np.append(self.classes_, unseen_label)\n",
        "            return np.where(y == e.args[0], unseen_label, super().transform(y))"
      ],
      "metadata": {
        "id": "sU3m4jEOyc_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "chunk_size = 50000\n",
        "#Number of Rows per Chunk\n",
        "chunks = pd.read_csv('/content/drive/MyDrive/dataset/TeamDeepwave/dataset/combined_file.csv', low_memory = False, chunksize = chunk_size)\n",
        "\n",
        "for i, chunks in enumerate(chunks):\n",
        "  chunks.to_csv(f'chunks_{i}.csv', index = False)"
      ],
      "metadata": {
        "id": "O4cVP9dAh1TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/cv-corpus-17.0-delta-2024-03-15/en'\n",
        "all_filenames = glob.glob(dataset_path + '/*.tsv')\n",
        "dataframes = [pd.read_csv(filename, sep='\\t', encoding='utf-8') for filename in all_filenames]\n",
        "combined_csv = pd.concat(dataframes)\n",
        "combined_csv.to_csv('/content/drive/MyDrive/dataset/TeamDeepwave/dataset/combined_file.csv', index=False, encoding='utf-8-sig')\n",
        "\"\"\"\n",
        "for filename in all_filenames:\n",
        "    df = pd.read_csv(filename, sep='\\t', encoding='utf-8')\n",
        "    dataframes.append(df)\n",
        "    combined_csv = pd.concat(dataframes)\n",
        "    combined_csv.to_csv('/content/drive/MyDrive/dataset/TeamDeepwave/dataset/combined_file.csv', index=False, encoding='utf-8-sig')\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "aiZ7FDJcbi-1",
        "outputId": "881a0da2-30e8-41a2-dfd7-d769b407623d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor filename in all_filenames:\\n    df = pd.read_csv(filename, sep='\\t', encoding='utf-8')\\n    dataframes.append(df)\\n    combined_csv = pd.concat(dataframes)\\n    combined_csv.to_csv('/content/drive/MyDrive/dataset/TeamDeepwave/dataset/combined_file.csv', index=False, encoding='utf-8-sig')\\n    \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_csv.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lps4DxT-opfQ",
        "outputId": "506d9df1-38e1-4257-bc1d-f61e492afea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           clip  duration[ms] client_id path sentence_id  \\\n",
            "0  common_voice_en_39863408.mp3        4140.0       NaN  NaN         NaN   \n",
            "1  common_voice_en_39944676.mp3        5832.0       NaN  NaN         NaN   \n",
            "2  common_voice_en_39762970.mp3        4176.0       NaN  NaN         NaN   \n",
            "3  common_voice_en_39958361.mp3        9036.0       NaN  NaN         NaN   \n",
            "4  common_voice_en_39916734.mp3        6984.0       NaN  NaN         NaN   \n",
            "5  common_voice_en_39590171.mp3        5148.0       NaN  NaN         NaN   \n",
            "6  common_voice_en_39939743.mp3        4068.0       NaN  NaN         NaN   \n",
            "7  common_voice_en_40103066.mp3        6840.0       NaN  NaN         NaN   \n",
            "8  common_voice_en_39634391.mp3        4176.0       NaN  NaN         NaN   \n",
            "9  common_voice_en_39859338.mp3        3636.0       NaN  NaN         NaN   \n",
            "\n",
            "  sentence sentence_domain  up_votes  down_votes  age gender accents  variant  \\\n",
            "0      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "1      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "2      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "3      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "4      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "5      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "6      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "7      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "8      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "9      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "\n",
            "  locale  segment reason source  is_used  clips_count  \n",
            "0    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "1    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "2    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "3    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "4    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "5    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "6    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "7    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "8    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "9    NaN      NaN    NaN    NaN      NaN          NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropna_csv = combined_csv.dropna()\n",
        "\n",
        "cleansed_csv = combined_csv.dropna(how = 'all')\n",
        "print(\"DataFrame with rows dropped where any column has NaN:\")\n",
        "print(dropna_csv.head(10))\n",
        "\n",
        "print(\"\\nDataFrame with rows dropped where all columns are NaN:\")\n",
        "print(cleansed_csv.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIuHky28pC4R",
        "outputId": "7e957014-0a1d-4535-e0bf-8b498f727773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with rows dropped where any column has NaN:\n",
            "Empty DataFrame\n",
            "Columns: [clip, duration[ms], client_id, path, sentence_id, sentence, sentence_domain, up_votes, down_votes, age, gender, accents, variant, locale, segment, reason, source, is_used, clips_count]\n",
            "Index: []\n",
            "\n",
            "DataFrame with rows dropped where all columns are NaN:\n",
            "                           clip  duration[ms] client_id path sentence_id  \\\n",
            "0  common_voice_en_39863408.mp3        4140.0       NaN  NaN         NaN   \n",
            "1  common_voice_en_39944676.mp3        5832.0       NaN  NaN         NaN   \n",
            "2  common_voice_en_39762970.mp3        4176.0       NaN  NaN         NaN   \n",
            "3  common_voice_en_39958361.mp3        9036.0       NaN  NaN         NaN   \n",
            "4  common_voice_en_39916734.mp3        6984.0       NaN  NaN         NaN   \n",
            "5  common_voice_en_39590171.mp3        5148.0       NaN  NaN         NaN   \n",
            "6  common_voice_en_39939743.mp3        4068.0       NaN  NaN         NaN   \n",
            "7  common_voice_en_40103066.mp3        6840.0       NaN  NaN         NaN   \n",
            "8  common_voice_en_39634391.mp3        4176.0       NaN  NaN         NaN   \n",
            "9  common_voice_en_39859338.mp3        3636.0       NaN  NaN         NaN   \n",
            "\n",
            "  sentence sentence_domain  up_votes  down_votes  age gender accents  variant  \\\n",
            "0      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "1      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "2      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "3      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "4      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "5      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "6      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "7      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "8      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "9      NaN             NaN       NaN         NaN  NaN    NaN     NaN      NaN   \n",
            "\n",
            "  locale  segment reason source  is_used  clips_count  \n",
            "0    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "1    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "2    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "3    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "4    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "5    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "6    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "7    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "8    NaN      NaN    NaN    NaN      NaN          NaN  \n",
            "9    NaN      NaN    NaN    NaN      NaN          NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tsv_read = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/cv-corpus-17.0-delta-2024-03-15/en/validated.tsv'\n",
        "df = pd.read_csv(tsv_read, sep='\\t', encoding='utf-8')\n",
        "tsv_filename = glob.glob(tsv_read + '/*.tsv')\n",
        "\n",
        "for filename in tsv_filename:\n",
        "    df = pd.read_csv(filename, sep='\\t', encoding='utf-8')\n",
        "\n",
        "print(f\"Inspecting{filename}:\")\n",
        "print(df.head(10))\n",
        "print(df.shape)\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "Rc4uneGqpTnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed28d122-1636-4de9-d0ac-e8517be3192a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inspecting/content/drive/MyDrive/dataset/TeamDeepwave/dataset/cv-corpus-17.0-delta-2024-03-15/en/unvalidated_sentences.tsv:\n",
            "                                           client_id  \\\n",
            "0  01e8ea298cdecf26e273f5baac3915eb992c493f229686...   \n",
            "1  02cbc1fe01fc67fa72c6e067fbe020399082efbeb57a2b...   \n",
            "2  03b62f72067ec967c423852bef03d1b61e63c156d86f6e...   \n",
            "3  05112cb5965431bbd47abd29b4faea9fb009b5a2e320e0...   \n",
            "4  05d33ad00cc2754da8e542a33a5255f9346535ef1d8619...   \n",
            "5  08072f2de4dcc2bfec5058dca41eb9535b61ccd193ecc4...   \n",
            "6  083af8bc921baf15ad5d8c8c876f4ecaf4f52bf6370161...   \n",
            "7  09c60e79113b346bbc1009fe21c46f273d09e62b0a73af...   \n",
            "8  0a0db76f30e3d011216425efa204fa0d3064767656b913...   \n",
            "9  0d6f10e8503355612e903ececf61788f7bfa18aee68ebc...   \n",
            "\n",
            "                           path  \\\n",
            "0  common_voice_en_39751075.mp3   \n",
            "1  common_voice_en_39589864.mp3   \n",
            "2  common_voice_en_40087973.mp3   \n",
            "3  common_voice_en_39587246.mp3   \n",
            "4  common_voice_en_40117514.mp3   \n",
            "5  common_voice_en_39603786.mp3   \n",
            "6  common_voice_en_39603175.mp3   \n",
            "7  common_voice_en_39694056.mp3   \n",
            "8  common_voice_en_40048623.mp3   \n",
            "9  common_voice_en_39644687.mp3   \n",
            "\n",
            "                                         sentence_id  \\\n",
            "0  e5e7d4694b7160add018a08876327f254690c1ab4c39ea...   \n",
            "1  e3e7c913ce32a3b5a58dda5fa1d855f2529ed36e1fa33f...   \n",
            "2  e90c361c9684d01d31bc6e8df3060bc97e536ca707bef4...   \n",
            "3  e3a1d0662e080f880a899b5a5226af16acf61360b1128e...   \n",
            "4  e9475052b6e625f8c5890389e4ffc17a1078dec1483592...   \n",
            "5  e4657d8d47be955eb14e04cd1c2a2b9ef89d310f639678...   \n",
            "6  e443f322884c5440d7f5072f21c5b0e1f0433ba6147471...   \n",
            "7  e5675cf954e759047939511360baf3b7cb19675c36781a...   \n",
            "8  e8d41398f8083305ed38cbd768b3d9315f8eb07cfb8bef...   \n",
            "9  e4f122417e91935105b1e356d982475afa7f1fb6945130...   \n",
            "\n",
            "                                            sentence sentence_domain  \\\n",
            "0  Madin was a significant figure of post-war Bir...             NaN   \n",
            "1    Alexandria and Texas were shut down mid-season.             NaN   \n",
            "2                           No runoff was necessary.             NaN   \n",
            "3  He was temporarily in charge of consular affai...             NaN   \n",
            "4                          It was a sickening sight.             NaN   \n",
            "5  It is made by mounting a sidecar to a regular ...             NaN   \n",
            "6  Within his genre, Di Giorgio is respected for ...             NaN   \n",
            "7          It is the only Paxton Township statewide.             NaN   \n",
            "8  Sharon decided not to proceed with their demol...             NaN   \n",
            "9                         He is an active Christian.             NaN   \n",
            "\n",
            "   up_votes  down_votes       age          gender  \\\n",
            "0         2           0       NaN             NaN   \n",
            "1         2           0       NaN             NaN   \n",
            "2         2           0     teens     transgender   \n",
            "3         2           0       NaN             NaN   \n",
            "4         2           0  twenties  male_masculine   \n",
            "5         2           0   sixties  male_masculine   \n",
            "6         2           0       NaN             NaN   \n",
            "7         3           0       NaN             NaN   \n",
            "8         2           0  twenties  male_masculine   \n",
            "9         2           0       NaN             NaN   \n",
            "\n",
            "                                             accents  variant locale  segment  \n",
            "0             United States English,New York English      NaN     en      NaN  \n",
            "1                                                NaN      NaN     en      NaN  \n",
            "2                                   Scottish English      NaN     en      NaN  \n",
            "3                                                NaN      NaN     en      NaN  \n",
            "4                                 Australian English      NaN     en      NaN  \n",
            "5                              United States English      NaN     en      NaN  \n",
            "6                                   Northern English      NaN     en      NaN  \n",
            "7       United States English,Transgender,California      NaN     en      NaN  \n",
            "8  India and South Asia (India, Pakistan, Sri Lanka)      NaN     en      NaN  \n",
            "9                                                NaN      NaN     en      NaN  \n",
            "(1877, 13)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1877 entries, 0 to 1876\n",
            "Data columns (total 13 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   client_id        1877 non-null   object \n",
            " 1   path             1877 non-null   object \n",
            " 2   sentence_id      1877 non-null   object \n",
            " 3   sentence         1877 non-null   object \n",
            " 4   sentence_domain  1 non-null      object \n",
            " 5   up_votes         1877 non-null   int64  \n",
            " 6   down_votes       1877 non-null   int64  \n",
            " 7   age              1461 non-null   object \n",
            " 8   gender           1413 non-null   object \n",
            " 9   accents          1733 non-null   object \n",
            " 10  variant          0 non-null      float64\n",
            " 11  locale           1877 non-null   object \n",
            " 12  segment          0 non-null      float64\n",
            "dtypes: float64(2), int64(2), object(9)\n",
            "memory usage: 190.8+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentence_domain'] = df['sentence_domain'].fillna('Unknown')\n",
        "df_cleaned = df.dropna()\n",
        "print(combined_csv.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rD6XPXOumQ5",
        "outputId": "7bc7d68d-aa35-402f-9d57-7c808c08b317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['clip', 'duration[ms]', 'client_id', 'path', 'sentence_id', 'sentence',\n",
            "       'sentence_domain', 'up_votes', 'down_votes', 'age', 'gender', 'accents',\n",
            "       'variant', 'locale', 'segment', 'reason', 'source', 'is_used',\n",
            "       'clips_count'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'label' is the gender column and other columns are acoustic features\n",
        "X = combined_csv.drop(columns=['clips_count'])\n",
        "y = combined_csv['client_id']\n"
      ],
      "metadata": {
        "id": "SkWN4RR9bk5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=124)"
      ],
      "metadata": {
        "id": "y502XqPUbmyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extended_label_encoder = ExtendedLabelEncoder()"
      ],
      "metadata": {
        "id": "wxPU2RVZ0ECv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the 'sentence_id' column in the training set\n",
        "X_train['sentence_id'] = extended_label_encoder.fit_transform(X_train['sentence_id'])\n"
      ],
      "metadata": {
        "id": "I7I_DSaO0M3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric function\n",
        "def print_metrics(y_true, y_pred):\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "id": "JaJpclg1brFS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}