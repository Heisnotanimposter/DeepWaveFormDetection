# -*- coding: utf-8 -*-
"""Deepwave Audio Feature Extraction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13kevEhdQff4SM2RdVmETydcMSb5dKZO9
"""
from IPython.display import HTML

# Replace the placeholders with your actual GitHub path
def create_colab_button(github_path):
    template = '<a href="https://colab.research.google.com/github/{path}" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>'
    return HTML(template.format(path=github_path))

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import torch
import torchaudio
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import plotly.express as px
import librosa
import librosa.display
import IPython.display as ipd
import sklearn
import warnings
import seaborn as sns
warnings.filterwarnings('ignore')

train_csv=pd.read_csv('../input/train_metadata.csv')
train_csv.head()

base_dir = '../input//train_short_audio'
train_csv['full_path'] = base_dir+ '/' + train_csv['primary_label'] + '/' + train_csv['filename']
astfly = train_csv[train_csv['primary_label'] == "astfly"].sample(1, random_state = 33)['full_path'].values[0]
casvir = train_csv[train_csv['primary_label'] == 'casvir'].sample(1, random_state = 33)['full_path'].values[0]
subfly = train_csv[train_csv['primary_label'] == "subfly"].sample(1, random_state = 33)['full_path'].values[0]
wilfly = train_csv[train_csv['primary_label'] == 'wilfly'].sample(1, random_state = 33)['full_path'].values[0]
verdin = train_csv[train_csv['primary_label'] == 'verdin'].sample(1, random_state = 33)['full_path'].values[0]
solsan = train_csv[train_csv['primary_label'] == 'solsan'].sample(1, random_state = 33)['full_path'].values[0]
birds= ["astfly", "casvir", "subfly", "wilfly", "verdin",'solsan']

ipd.Audio(astfly)

ipd.Audio(casvir)

ipd.Audio(subfly)

ipd.Audio(solsan)

y, sr = librosa.load(subfly)
print('y:', y, '\n')
print('y shape:', np.shape(y), '\n')
print('Sample Rate (KHz):', sr, '\n')
print('Check Len of Audio:', np.shape(y)[0]/sr)

audio_file, _ = librosa.effects.trim(y)
print('Audio File:', audio_file, '\n')
print('Audio File shape:', np.shape(audio_file))

y_astfly, sr_astfly = librosa.load(astfly)
audio_astfly, _ = librosa.effects.trim(y_astfly)

y_casvir, sr_casvir = librosa.load(casvir)
audio_casvir, _ = librosa.effects.trim(y_casvir)

y_subfly, sr_subfly = librosa.load(subfly)
audio_subfly, _ = librosa.effects.trim(y_subfly)

y_wilfly, sr_wilfly = librosa.load(wilfly)
audio_wilfly, _ = librosa.effects.trim(y_wilfly)

y_verdin, sr_verdin = librosa.load(verdin)
audio_verdin, _ = librosa.effects.trim(y_verdin)

y_solsan, sr_solsan = librosa.load(solsan)
audio_solsan, _ = librosa.effects.trim(y_solsan)

fig, ax = plt.subplots(6, figsize = (16, 12))
fig.suptitle('Sound Waves', fontsize=16)

librosa.display.waveplot(y = audio_astfly, sr = sr_astfly, color = "#A300F9", ax=ax[0])
librosa.display.waveplot(y = audio_casvir, sr = sr_casvir, color = "#4300FF", ax=ax[1])
librosa.display.waveplot(y = audio_subfly, sr = sr_subfly, color = "#009DFF", ax=ax[2])
librosa.display.waveplot(y = audio_wilfly, sr = sr_wilfly, color = "#00FFB0", ax=ax[3])
librosa.display.waveplot(y = audio_verdin, sr = sr_verdin, color = "#D9FF00", ax=ax[4])
librosa.display.waveplot(y = audio_solsan, sr = sr_solsan, color = "r", ax=ax[5]);

for i, name in zip(range(6), birds):
    ax[i].set_ylabel(name, fontsize=13)

n_fft=2048
hop_length=512
# Short-time Fourier transform (STFT)
D_astfly = np.abs(librosa.stft(audio_astfly, n_fft = n_fft, hop_length = hop_length))
# Convert an amplitude spectrogram to Decibels-scaled spectrogram.
DB_astfly = librosa.amplitude_to_db(D_astfly, ref = np.max)
# === PLOT ===
fig, ax = plt.subplots(1, 1, figsize=(12, 6))
fig.suptitle('Log Frequency Spectrogram', fontsize=16)
# fig.delaxes(ax[1, 2])
img=librosa.display.specshow(DB_astfly, sr = sr_astfly, hop_length = hop_length, x_axis = 'time',
                         y_axis = 'log', cmap = 'cool', ax=ax)
ax.set_title('ASTFLY', fontsize=13)
plt.colorbar(img,ax=ax)

S, phase = librosa.magphase(librosa.stft(audio_astfly))
S_db=librosa.amplitude_to_db(S, ref=np.max)
rms = librosa.feature.rms(S=S)
fig, ax = plt.subplots(nrows=2, sharex=True,figsize = (16, 6))
times = librosa.times_like(rms)
ax[0].semilogy(times, rms[0], label='RMS Energy')
ax[0].set(xticks=[])
ax[0].legend()
ax[0].label_outer()
librosa.display.specshow(S_db,
                         y_axis='log', x_axis='time', ax=ax[1])
ax[1].set(title='log Power spectrogram')
plt.show()

# Create the Mel Spectrograms
S_astfly = librosa.feature.melspectrogram(audio_astfly, sr=sr_astfly)
S_DB_astfly = librosa.amplitude_to_db(S_astfly, ref=np.max)
# === PLOT ====
fig, ax = plt.subplots(1, 1, figsize=(12, 6))
fig.suptitle('Mel Spectrogram', fontsize=16)
img=librosa.display.specshow(S_DB_astfly, sr = sr_astfly, hop_length = hop_length, x_axis = 'time',
                         y_axis = 'log', cmap = 'cool', ax=ax)

ax.set_title('ASTFLY', fontsize=13)
plt.colorbar(img,ax=ax)

# Total zero_crossings in our 1 song
zero_astfly = librosa.zero_crossings(audio_astfly, pad=False)
zero_casvir = librosa.zero_crossings(audio_casvir, pad=False)
zero_wilfly = librosa.zero_crossings(audio_wilfly, pad=False)
zero_subfly = librosa.zero_crossings(audio_subfly, pad=False)
zero_verdin = librosa.zero_crossings(audio_verdin, pad=False)
zero_solsan = librosa.zero_crossings(audio_solsan, pad=False)
zero_birds_list = [zero_astfly, zero_casvir, zero_wilfly, zero_subfly, zero_verdin,zero_solsan]

for bird, name in zip(zero_birds_list, birds):
    print("{} change rate is {:,}".format(name, sum(bird)))

y_harm_casvir, y_perc_casvir = librosa.effects.hpss(audio_casvir)
D_casvir = np.abs(librosa.stft(audio_casvir, n_fft = n_fft, hop_length = hop_length))
DB_casvir = librosa.amplitude_to_db(D_casvir, ref = np.max)
plt.figure(figsize = (16, 6))
plt.plot(y_perc_casvir, color = '#FFB100')
plt.plot(y_harm_casvir, color = '#A300F9')
plt.legend(("Perceptrual", "Harmonics"))
plt.title("Harmonics + Percussive : Casvir Bird", fontsize=16);


H, P = librosa.decompose.hpss(librosa.stft(audio_casvir))
plt.figure(figsize=(16, 6))
plt.subplot(3, 1, 1)
librosa.display.specshow(DB_casvir, y_axis='log')
plt.colorbar(format='%+2.0f dB')
plt.title('Full power spectrogram: Harmonic + Percussive')

# harmonic spectrogram will show more horizontal/pitch-dependent changes
plt.subplot(3, 1, 2)
librosa.display.specshow(librosa.amplitude_to_db(np.abs(H), ref=np.max), y_axis='log')
plt.colorbar(format='%+2.0f dB')
plt.title('Harmonic power spectrogram')
plt.subplot(3, 1, 3)

# percussive spectrogram will show more vertical/time-dependent changes
librosa.display.specshow(librosa.amplitude_to_db(np.abs(P), ref=np.max), y_axis='log')
plt.colorbar(format='%+2.0f dB')
plt.title('Percussive power spectrogram')
plt.tight_layout()
plt.show()

tempo, beat_frames = librosa.beat.beat_track(y=y_harm_casvir, sr=sr_casvir)
print('Detected Tempo: '+ str(tempo) + ' beats/min')
beat_times = librosa.frames_to_time(beat_frames, sr=sr)
beat_time_diff = np.ediff1d(beat_times)
beat_nums = np.arange(1, np.size(beat_times))
fig, ax = plt.subplots()
fig.set_size_inches(20, 5)
ax.set_ylabel("Time difference (s)")
ax.set_xlabel("Beats")
g = sns.barplot(beat_nums, beat_time_diff, palette="rocket",ax=ax)
g = g.set(xticklabels=[])

# Create Tempo BPM variable
tempo_astfly, _ = librosa.beat.beat_track(y_astfly, sr = sr_astfly)
tempo_casvir, _ = librosa.beat.beat_track(y_casvir, sr = sr_casvir)
tempo_wilfly, _ = librosa.beat.beat_track(y_wilfly, sr = sr_wilfly)
tempo_subfly, _ = librosa.beat.beat_track(y_subfly, sr = sr_subfly)
tempo_verdin, _ = librosa.beat.beat_track(y_verdin, sr = sr_verdin)
tempo_solsan, _ = librosa.beat.beat_track(y_solsan, sr = sr_solsan)
data = pd.DataFrame({"Type": birds ,
                     "BPM": [tempo_astfly, tempo_casvir, tempo_wilfly, tempo_subfly, tempo_verdin,tempo_solsan] })


# Plot
plt.figure(figsize = (16, 6))
ax = sns.barplot(y = data["BPM"], x = data["Type"], palette="rocket")
plt.ylabel("BPM", fontsize=14)
plt.yticks(fontsize=13)
plt.xticks(fontsize=13)
plt.xlabel("")
plt.title("BPM for 6 Different Bird Species", fontsize=16);

chroma=librosa.feature.chroma_stft(y=audio_casvir, sr=sr_casvir)
fig, ax = plt.subplots(1,figsize = (10, 5))
img = librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', ax=ax)
fig.colorbar(img, ax=ax)
ax.set(title='Chromagram')

#using an energy(magnitude) spectrum
S = np.abs(librosa.stft(audio_casvir))
chroma = librosa.feature.chroma_stft(S=S, sr=sr_casvir)#applying the logarithmic fourier transform
fig, ax = plt.subplots(1,figsize = (10, 5))
img = librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', ax=ax)
fig.colorbar(img, ax=ax)
ax.set(title='Chromagram')

chroma_stft = librosa.feature.chroma_stft(y=audio_casvir, sr=sr_casvir)
chroma_cq = librosa.feature.chroma_cqt(y=audio_casvir, sr=sr_casvir)
fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True,figsize = (10, 9))
librosa.display.specshow(chroma_stft, y_axis='chroma', x_axis='time', ax=ax[0])
ax[0].set(title='chroma_stft')
ax[0].label_outer()
img = librosa.display.specshow(chroma_cq, y_axis='chroma', x_axis='time', ax=ax[1])
ax[1].set(title='chroma_cqt')
# ax[1].label_outer()
# img = librosa.display.specshow(chroma_cens, y_axis='chroma', x_axis='time', ax=ax[2])
# ax[2].set(title='chroma_cens')
fig.colorbar(img, ax=ax)

chroma_stft = librosa.feature.chroma_stft(y=audio_casvir, sr=sr_casvir)
chroma_cens = librosa.feature.chroma_cens(y=audio_casvir, sr=sr_casvir)

fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True,figsize = (10, 9))
librosa.display.specshow(chroma_stft, y_axis='chroma', x_axis='time', ax=ax[0])
ax[0].set(title='chroma_stft')
ax[0].label_outer()

img = librosa.display.specshow(chroma_cens, y_axis='chroma', x_axis='time', ax=ax[1])
ax[1].set(title='chroma_cens')
fig.colorbar(img, ax=ax)

# Calculate the Spectral Centroids
spectral_centroids = librosa.feature.spectral_centroid(audio_casvir, sr=sr_casvir)[0]

# Shape is a vector
print('Centroids:', spectral_centroids, '\n')
print('Shape of Spectral Centroids:', spectral_centroids.shape, '\n')

# Computing the time variable for visualization
frames = range(len(spectral_centroids))

# Converts frame counts to time (seconds)
t = librosa.frames_to_time(frames)

print('frames:', frames, '\n')
print('t:', t)

# Function that normalizes the Sound Data
def normalize(x, axis=0):
    return sklearn.preprocessing.minmax_scale(x, axis=axis)
#Plotting the Spectral Centroid along the waveform
plt.figure(figsize = (16, 6))
librosa.display.waveplot(audio_casvir, sr=sr_casvir, alpha=0.4, color = '#A300F9', lw=3)
plt.plot(t, normalize(spectral_centroids), color='#FFB100', lw=2)
plt.legend(["Spectral Centroid", "Wave"])
plt.title("Spectral Centroid: Casvir Bird", fontsize=16);

contrast = librosa.feature.spectral_contrast(y=y_harm_casvir,sr=sr_casvir)
plt.figure(figsize=(15,5))
librosa.display.specshow(contrast, x_axis='time')
plt.colorbar()
plt.ylabel('Frequency bands')
plt.title('Spectral contrast')

mfcc=librosa.feature.mfcc(y=audio_astfly, sr=sr_astfly)
fig, ax = plt.subplots(1,figsize = (12, 6))
img = librosa.display.specshow(mfcc, x_axis='time', ax=ax)
print(mfcc.shape)
fig.colorbar(img, ax=ax)
ax.set(title='MFCC')

"""**References:**
* https://www.kaggle.com/andradaolteanu/birdcall-recognition-eda-and-audio-fe
* https://rramnauth2220.github.io/blog/posts/code/200525-feature-extraction.html
"""