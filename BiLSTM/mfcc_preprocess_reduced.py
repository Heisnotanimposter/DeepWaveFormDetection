# -*- coding: utf-8 -*-
"""mfcc_preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s0vZ-xKkkpLUmde0ZJ-2CSImpMNOag5X
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import glob
import numpy as np
import librosa
from tqdm import tqdm

# Configuration class
class Config:
    SR = 32000  # Sampling rate
    N_MFCC = 13  # Number of MFCC features
    ROOT_FOLDER = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/open/'  # Dataset root folder
    N_CLASSES = 2  # Number of classes for classification
    MAX_SEQ_LEN = 200  # Maximum sequence length for input to the model
    SEED = 42  # Seed for reproducibility

CONFIG = Config()

# Function to load file paths
def load_file_paths(root_folder, subfolder):
    file_paths = glob.glob(os.path.join(root_folder, subfolder, '*.ogg'))
    print(f"Loaded {len(file_paths)} files from {os.path.join(root_folder, subfolder)}")
    return file_paths

# Function to get MFCC features
def get_mfcc_feature(file_paths):
    features = []
    labels = []
    for file_path in tqdm(file_paths):
        try:
            print(f"Processing file: {file_path}")  # Debug print
            y, sr = librosa.load(file_path, sr=CONFIG.SR)
            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG.N_MFCC)
            pad_width = CONFIG.MAX_SEQ_LEN - mfcc.shape[1]
            if pad_width > 0:
                mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')
            else:
                mfcc = mfcc[:, :CONFIG.MAX_SEQ_LEN]
            features.append(mfcc)

            # Assuming labels are derived from file names (e.g., 'fake' or 'real')
            if 'fake' in file_path:
                label_vector = [1, 0]
            else:
                label_vector = [0, 1]
            labels.append(label_vector)
        except Exception as e:
            print(f"Error loading {file_path}: {e}")

    return np.array(features), np.array(labels)

# Load file paths
train_files = load_file_paths(CONFIG.ROOT_FOLDER, 'reduced_train')
test_files = load_file_paths(CONFIG.ROOT_FOLDER, 'reduced_test')

train_csv = load_file_paths(CONFIG.ROOT_FOLDER, 'reduced_train.csv')
test_csv = load_file_paths(CONFIG.ROOT_FOLDER, 'reduced_test.csv')

# Extract features
train_mfcc, train_labels = get_mfcc_feature(train_files)
test_mfcc, test_labels = get_mfcc_feature(test_files)

# Save the data using numpy
np.save('train_mfcc.npy', train_mfcc)
np.save('train_labels.npy', train_labels)
np.save('test_mfcc.npy', test_mfcc)
np.save('test_labels.npy', test_labels)

print(f'Training and validation features and labels saved successfully.')

# Load the data using numpy
train_mfcc_loaded = np.load('train_mfcc.npy')
train_labels_loaded = np.load('train_labels.npy')
test_mfcc_loaded = np.load('test_mfcc.npy')
test_labels_loaded = np.load('test_labels.npy')

# Verify the shapes of the loaded features and labels
print(f'train_mfcc_loaded shape: {train_mfcc_loaded.shape}')
print(f'train_labels_loaded shape: {train_labels_loaded.shape}')
print(f'test_mfcc_loaded shape: {test_mfcc_loaded.shape}')
print(f'test_labels_loaded shape: {test_labels_loaded.shape}')

# Verify the data integrity by comparing the original and loaded data
print(f'Training features match: {np.array_equal(train_mfcc, train_mfcc_loaded)}')
print(f'Training labels match: {np.array_equal(train_labels, train_labels_loaded)}')
print(f'Testing features match: {np.array_equal(test_mfcc, test_mfcc_loaded)}')
print(f'Testing labels match: {np.array_equal(test_labels, test_labels_loaded)}')

import h5py

# Save the data to an HDF5 file
with h5py.File('dataset.h5', 'w') as f:
    f.create_dataset('train_mfcc', data=train_mfcc)
    f.create_dataset('train_labels', data=train_labels)
    f.create_dataset('test_mfcc', data=test_mfcc)
    f.create_dataset('test_labels', data=test_labels)

print(f'Training and validation features and labels saved successfully in HDF5 format.')

# Load the data from the HDF5 file
with h5py.File('dataset.h5', 'r') as f:
    train_mfcc = f['train_mfcc'][:]
    train_labels = f['train_labels'][:]
    test_mfcc = f['test_mfcc'][:]
    test_labels = f['test_labels'][:]

print(f'Training and validation features and labels loaded successfully from HDF5 format.')

