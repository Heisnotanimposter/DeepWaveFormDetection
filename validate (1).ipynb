{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqsgdJLxhT2w",
        "outputId": "a6327e1c-2052-4a88-9401-61d91ab02bce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03eK_cSig_Xl",
        "outputId": "8993466f-4d81-485f-f366-61fa1210eb96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for .png files in: /content/drive/MyDrive/dataset/TeamDeepwave/dataset/preprocessed/test\n",
            "Loaded 50000 test files.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:   4%|â–Ž         | 14/391 [07:25<2:39:33, 25.39s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    ROOT_FOLDER = '/content/drive/MyDrive/dataset/TeamDeepwave/dataset/preprocessed/'\n",
        "    BATCH_SIZE = 128  # Increased batch size\n",
        "    MODEL_PATH = '/content/drive/MyDrive/dataset/TeamDeepwave/sample_Lee/sample_2500/1.pt'  # Path to your best model\n",
        "\n",
        "CONFIG = Config()\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Custom Dataset for Mel-spectrogram images\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, mel_files, transform=None):\n",
        "        self.mel_files = mel_files\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mel_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mel_image = Image.open(self.mel_files[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            mel_image = self.transform(mel_image)\n",
        "        return mel_image\n",
        "\n",
        "# Load file paths for the test dataset\n",
        "def load_test_file_paths(root_folder):\n",
        "    test_folder = os.path.join(root_folder, 'test')\n",
        "    print(f\"Looking for .png files in: {test_folder}\")\n",
        "    try:\n",
        "        mel_files = glob.glob(os.path.join(test_folder, '*.png'))\n",
        "        if not mel_files:\n",
        "            raise FileNotFoundError(f\"No .png files found in {test_folder}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing the directory: {e}\")\n",
        "        mel_files = []\n",
        "    return mel_files\n",
        "\n",
        "# Data transformations for Mel-spectrogram images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load test file paths\n",
        "test_mel_files = load_test_file_paths(CONFIG.ROOT_FOLDER)\n",
        "\n",
        "# Ensure non-empty loaders\n",
        "if not test_mel_files:\n",
        "    raise ValueError(\"No test files found. Ensure the test directory contains .png files.\")\n",
        "\n",
        "print(f\"Loaded {len(test_mel_files)} test files.\")\n",
        "\n",
        "# Create test dataset and loader\n",
        "test_dataset = CustomDataset(test_mel_files, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG.BATCH_SIZE, shuffle=False, num_workers=4)  # Increase num_workers\n",
        "\n",
        "# Define the CNN model for Mel-spectrogram images (same as the one used during training)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 256)\n",
        "        self.fc2 = nn.Linear(256, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.gelu(self.conv1(x)))\n",
        "        x = self.pool(F.gelu(self.conv2(x)))\n",
        "        x = self.pool(F.gelu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 16 * 16)\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model and load the state dictionary\n",
        "model = CNN(output_dim=2).to(device)\n",
        "model.load_state_dict(torch.load(CONFIG.MODEL_PATH, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Prediction on test dataset\n",
        "def predict(model, loader, device):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for mel in tqdm(loader, desc=\"Predicting\", leave=False):\n",
        "            mel = mel.to(device)\n",
        "            outputs = model(mel)\n",
        "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            all_predictions.extend(probs.cpu().numpy())\n",
        "    return np.array(all_predictions)\n",
        "\n",
        "# Predict on test data\n",
        "test_predictions = predict(model, test_loader, device)\n",
        "\n",
        "# Create a DataFrame for submission\n",
        "submission_df = pd.DataFrame(test_predictions, columns=['fake', 'real'])\n",
        "\n",
        "# Extracting IDs from test file paths\n",
        "test_ids = [os.path.basename(f).replace('.png', '') for f in test_mel_files]\n",
        "submission_df.insert(0, 'id', test_ids)\n",
        "\n",
        "# Save to CSV\n",
        "submission_csv_path = '/content/drive/MyDrive/submission.csv'\n",
        "submission_df.to_csv(submission_csv_path, index=False)\n",
        "print(f'Submission file created at {submission_csv_path}!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOT7nVARhEn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1UUls1asJnA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}